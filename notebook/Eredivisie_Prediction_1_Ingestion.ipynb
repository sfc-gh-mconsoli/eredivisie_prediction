{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b402a9c-84ec-4818-ab34-967764d3f6fc",
   "metadata": {
    "name": "Intro",
    "collapsed": false
   },
   "source": "# ⚽ **HOL: Eredivisie Prediction** 🥇\n### Notebook - Data Ingestion - 1/4\n\n---\n\n\n### What We'll Do:\n1. -> **Data Ingestion**: Fetch Eredivisie data from the GitHub repository.\n2. **Data Transformation**: Utilize Snowpark DataFrames for data preparation and analysis.\n3. **Model Training**: Train model and store it in the Snowflake Model Registry\n4. **Prediction**: Predict who is going to win Eredivisie 2024/2025\n\n![Eredivisie](https://64.media.tumblr.com/a1d3bc556ab9711ed0b57c02aa1264a8/874fef2692632b47-f4/s540x810/48bf693b3002d223526fe26b8dba3d3db88023d1.gif)\n"
  },
  {
   "cell_type": "markdown",
   "id": "898f2e7c-3f14-41a1-baeb-c1a48579f43e",
   "metadata": {
    "name": "Pre_Reqs",
    "collapsed": false
   },
   "source": "⚠️ *If you are using a Snowflake Trial account, you should execute the `setup_trial.sql` and upload dataset manually to stage. Once completed, you can move directly to the data transformation notebook, or you can jump to the cell in this notebook `\"Verify_Data_Loaded_1\"`.* Before to do so, on the top right **Packages** tab, let's import the `plotly` library and click on the **Start** button.\n\n### Setup\n\nBefore using this notebook, ensure that you have created the following objects by running the `setup.sql` script in a worksheet:\n\n- **Database**: `EREDIVISIE_PREDICTION`\n- **Schema**: `RAW_DATA`\n- **Warehouse**: `EREDIVISIE_PREDICTION_WH`\n- **Network Rule**: `GITHUB_NETWORK_RULE`\n- **External Access Integration**: `GITHUB_EXTERNAL_ACCESS_INTEGRATION`\n\nThe first three items are required as you will need to define the Database, Schema, and Warehouse when you import this notebook into the Snowflake UI.\n\nFor the **Network Rule** and **External Access Integration**, once created, follow these steps to make them available within this notebook:\n\n1. **Click on Notebook Settings** (located at the top right of the worksheet screen).\n2. **Select the External Access Tab**.\n3. **Enable** `GITHUB_EXTERNAL_ACCESS_INTEGRATION` from the list.\n4. ++ On the top right **Packages** tab, let's import the `plotly` library. It's not related to the external access, but we'll need it at the end of the notebook. \n4. **Reload the Notebook**. Once reloaded, you will have access to the GitHub URL directly from this notebook.\n\nWith these configurations in place, you’ll be ready to extract and work with the dataset from the external GitHub URL in the following cells.\n\n---\n"
  },
  {
   "cell_type": "markdown",
   "id": "7d11f051-49fa-4435-9227-bea659d94a78",
   "metadata": {
    "name": "_Step_1_Data_Loading",
    "collapsed": false
   },
   "source": "## Step 1: Data Loading\n---\n\nIn this notebook, we will use Python functions and External Access Integration to load and analyze data about Eredivisie from 1995 to 2023. Our data source is a GitHub repository, from which we'll fetch and directly store historical data in our Snowflake account. No S3 buckets or local downloads are needed — our goal is to simplify the execution of this Hands-On Lab (HOL) while showcasing the extensive capabilities of Snowflake!\n\nThe next cells will perform the following actions:\n\n- Creating Function to fetch data from external API / GitHub\n- Create tables automatically \n- Verify data loaded\n\nLet's get it done! "
  },
  {
   "cell_type": "code",
   "id": "9908f3ab-97f1-4610-8674-8655b80862d3",
   "metadata": {
    "language": "python",
    "name": "Get_Active_Session",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark import Session\n\nsession = get_active_session()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e00475bc-49df-4635-bd32-f4c8eb4c8225",
   "metadata": {
    "language": "sql",
    "name": "Use_Role_Enforcement",
    "collapsed": false
   },
   "outputs": [],
   "source": "--Note: For this Hands-On Lab (HOL), we are not creating ad hoc roles and users to minimize prerequisites and simplify setup.\n\nUSE ROLE ACCOUNTADMIN;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "208cbcf7-db40-4a95-8f53-518bb1fe92a1",
   "metadata": {
    "language": "python",
    "name": "Create_Fetch_Data_Function",
    "collapsed": false
   },
   "outputs": [],
   "source": "import requests\nimport pandas as pd\nfrom snowflake.snowpark import DataFrame as df\nfrom io import StringIO\n\ndef fetch_dataset_from_github(url: str) -> 'DataFrame':\n    # Fetch the CSV data from the URL\n    response = requests.get(url)\n    if response.status_code == 200:\n        # Decode the content and read into a Pandas DataFrame\n        csv_data = response.content.decode('utf-8')\n        csv_file = StringIO(csv_data)\n        pandas_df = pd.read_csv(csv_file)\n        \n        # Convert Pandas DataFrame to Snowpark DataFrame\n        return session.create_dataframe(pandas_df)\n    else:\n        raise Exception(f\"Failed to fetch CSV: {response.status_code} - {response.text}\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "00876816-7aa0-4300-8373-5de754927d78",
   "metadata": {
    "language": "python",
    "name": "Load_All_Data",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Once an updated file is on the github dataset repo, it's enoguh to run this cell to reload the new datasets.\nfrom snowflake.snowpark.functions import col\n\n# Function to rename columns to uppercase\ndef rename_columns_to_uppercase(df):\n    # Generate a list of columns with uppercase names\n    new_columns = [col(c).alias(c.upper()) for c in df.columns]\n    # Select columns with new names\n    return df.select(*new_columns)\n\n# Base URL and list of files\nurl_base = 'https://github.com/sfc-gh-mconsoli/eredivisie_prediction/raw/main/dataset/'\nurl_files = [\n    'eredivisie_history.csv',\n    'eredivisie_fixture.csv'\n]\n\n# Loop through each URL\nfor url in url_files:\n    # Get Snowpark DataFrame from the URL\n    df = fetch_dataset_from_github(url_base + url)\n\n    # Extract table name from URL\n    table_name = url.split('/')[-1].replace('.csv', '').upper()\n\n    # Drop the table if it exists\n    session.sql(f\"DROP TABLE IF EXISTS {table_name}\").collect()\n\n    # Convert column names to uppercase\n    df = rename_columns_to_uppercase(df)\n\n    # Create table and insert data from Snowpark DataFrame\n    df.write.save_as_table(table_name, mode='overwrite')\n\n    print(f\"Table {table_name} created and data loaded successfully.\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fc221afd-5cf4-4877-81f2-341b5a794274",
   "metadata": {
    "language": "python",
    "name": "Verify_Data_Loaded_1",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Let's check loaded data\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark import Session\nimport streamlit as st\n\nsession = get_active_session()\n\neredivisie_history_df = session.table('EREDIVISIE_HISTORY')\n\nst.dataframe(eredivisie_history_df)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "db058f60-3e5b-4a2f-863d-5aa0ff228e59",
   "metadata": {
    "language": "sql",
    "name": "Verify_Data_Loaded_2",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- Verify we loaded data for all seasons\nSELECT YEAR(TO_DATE(\"DATE\",'DD/MM/YYYY')), COUNT(*)\nFROM EREDIVISIE_PREDICTION.PUBLIC.EREDIVISIE_HISTORY\nGROUP BY YEAR(TO_DATE(\"DATE\",'DD/MM/YYYY'))\norder by YEAR(TO_DATE(\"DATE\",'DD/MM/YYYY'))  DESC",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d80c942b-3f67-4594-b779-4ec271a57374",
   "metadata": {
    "language": "python",
    "name": "Winner_Analysis",
    "collapsed": false
   },
   "outputs": [],
   "source": "import streamlit as st\nimport snowflake.snowpark as sp\nimport snowflake.snowpark.functions as F\nimport plotly.express as px\n\n# Filter home wins\nhome_wins = (\n    eredivisie_history_df.filter(F.col('FTR') == 'H')\n    .group_by('HOMETEAM')\n    .agg(F.count('HOMETEAM').alias('Wins'))\n)\n\n# Filter away wins\naway_wins = (\n    eredivisie_history_df.filter(F.col('FTR') == 'A')\n    .group_by('AWAYTEAM')\n    .agg(F.count('AWAYTEAM').alias('Wins'))\n)\n\n# Rename columns to match for concatenation\nhome_wins = home_wins.select(F.col('HOMETEAM').alias('Team'), 'Wins')\naway_wins = away_wins.select(F.col('AWAYTEAM').alias('Team'), 'Wins')\n\n# Combine home and away wins\ntotal_wins = home_wins.union_all(away_wins).group_by('Team').agg(F.sum('Wins').alias('Total_Wins'))\n\n# Collect the result into a Pandas DataFrame\ntotal_wins_pd = total_wins.to_pandas()\n# Sort by most wins\ntotal_wins_pd = total_wins_pd.sort_values(by='TOTAL_WINS', ascending=False)\n\n# Plotting the chart\n# Function to plot bar chart\ndef plot_bar_chart(df, x_col, y_col, title, labels):\n    fig = px.bar(df, x=x_col, y=y_col, title=title, labels=labels)\n    st.plotly_chart(fig)\n\n# Plot\n# Plot the chart for the team with most wins\nplot_bar_chart(\n    total_wins_pd, \n    'TEAM', \n    'TOTAL_WINS', \n    'Top Teams by Number of Wins', \n    {'TEAM': 'Team', 'TOTAL_WINS': 'Number of Wins'}\n)",
   "execution_count": null
  }
 ]
}