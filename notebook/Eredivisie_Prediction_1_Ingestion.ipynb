{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b402a9c-84ec-4818-ab34-967764d3f6fc",
   "metadata": {
    "name": "Intro",
    "collapsed": false
   },
   "source": "# âš½ **HOL: Eredivisie Prediction** ðŸ¥‡\n### Notebook - Data Ingestion - 1/4\n\n---\n\n\n### What We'll Do:\n1. -> **Data Ingestion**: Fetch Eredivisie data from the GitHub repository.\n2. **Data Transformation**: Utilize Snowpark DataFrames for data preparation and analysis.\n3. **Model Training**: Train model and store it in the Snowflake Model Registry\n4. **Prediction**: Predict who is going to win Eredivisie 2024/2025\n\n![Eredivisie](https://64.media.tumblr.com/a1d3bc556ab9711ed0b57c02aa1264a8/874fef2692632b47-f4/s540x810/48bf693b3002d223526fe26b8dba3d3db88023d1.gif)\n"
  },
  {
   "cell_type": "markdown",
   "id": "898f2e7c-3f14-41a1-baeb-c1a48579f43e",
   "metadata": {
    "name": "Pre_Reqs",
    "collapsed": false
   },
   "source": "âš ï¸ *If you are using a Snowflake Trial account, you should execute the `setup_trial.sql` and upload dataset manually to stage. Once completed, you can move directly to the data transformation notebook, or you can jump to the cell in this notebook `\"Verify_Data_Loaded_1\"`.* Before to do so, on the top right **Packages** tab, let's import the `plotly` library and click on the **Start** button.\n\n### Setup\n\nBefore using this notebook, ensure that you have created the following objects by running the `setup.sql` script in a worksheet:\n\n- **Database**: `EREDIVISIE_PREDICTION`\n- **Schema**: `RAW_DATA`\n- **Warehouse**: `EREDIVISIE_PREDICTION_WH`\n- **Network Rule**: `GITHUB_NETWORK_RULE`\n- **External Access Integration**: `GITHUB_EXTERNAL_ACCESS_INTEGRATION`\n\nThe first three items are required as you will need to define the Database, Schema, and Warehouse when you import this notebook into the Snowflake UI.\n\nFor the **Network Rule** and **External Access Integration**, once created, follow these steps to make them available within this notebook:\n\n1. **Click on Notebook Settings** (located at the top right of the worksheet screen).\n2. **Select the External Access Tab**.\n3. **Enable** `GITHUB_EXTERNAL_ACCESS_INTEGRATION` from the list.\n4. ++ On the top right **Packages** tab, let's import the `plotly` library. It's not related to the external access, but we'll need it at the end of the notebook. \n4. **Reload the Notebook**. Once reloaded, you will have access to the GitHub URL directly from this notebook.\n\nWith these configurations in place, youâ€™ll be ready to extract and work with the dataset from the external GitHub URL in the following cells.\n\n---\n"
  },
  {
   "cell_type": "markdown",
   "id": "7d11f051-49fa-4435-9227-bea659d94a78",
   "metadata": {
    "name": "_Step_1_Data_Loading",
    "collapsed": false
   },
   "source": "## Step 1: Data Loading\n---\n\nIn this notebook, we will use Python functions and External Access Integration to load and analyze data about Eredivisie from 1995 to 2023. Our data source is a GitHub repository, from which we'll fetch and directly store historical data in our Snowflake account. No S3 buckets or local downloads are needed â€” our goal is to simplify the execution of this Hands-On Lab (HOL) while showcasing the extensive capabilities of Snowflake!\n\nThe next cells will perform the following actions:\n\n- Creating Function to fetch data from external API / GitHub\n- Create tables automatically \n- Verify data loaded\n\nLet's get it done! "
  },
  {
   "cell_type": "code",
   "id": "9908f3ab-97f1-4610-8674-8655b80862d3",
   "metadata": {
    "language": "python",
    "name": "Get_Active_Session",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark import Session\n\nsession = get_active_session()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e00475bc-49df-4635-bd32-f4c8eb4c8225",
   "metadata": {
    "language": "sql",
    "name": "Use_Role_Enforcement",
    "collapsed": false
   },
   "outputs": [],
   "source": "--Note: For this Hands-On Lab (HOL), we are not creating ad hoc roles and users to minimize prerequisites and simplify setup.\n\nUSE ROLE ACCOUNTADMIN;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "208cbcf7-db40-4a95-8f53-518bb1fe92a1",
   "metadata": {
    "language": "python",
    "name": "Create_Fetch_Data_Function",
    "collapsed": false
   },
   "outputs": [],
   "source": "import requests\nimport pandas as pd\nfrom snowflake.snowpark import DataFrame as df\nfrom io import StringIO\n\ndef fetch_dataset_from_github(url: str) -> 'DataFrame':\n    # Fetch the CSV data from the URL\n    response = requests.get(url)\n    if response.status_code == 200:\n        # Decode the content and read into a Pandas DataFrame\n        csv_data = response.content.decode('utf-8')\n        csv_file = StringIO(csv_data)\n        pandas_df = pd.read_csv(csv_file)\n        \n        # Convert Pandas DataFrame to Snowpark DataFrame\n        return session.create_dataframe(pandas_df)\n    else:\n        raise Exception(f\"Failed to fetch CSV: {response.status_code} - {response.text}\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "00876816-7aa0-4300-8373-5de754927d78",
   "metadata": {
    "language": "python",
    "name": "Load_All_Data",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Once an updated file is on the github dataset repo, it's enoguh to run this cell to reload the new datasets.\nfrom snowflake.snowpark.functions import col\n\n# Function to rename columns to uppercase\ndef rename_columns_to_uppercase(df):\n    # Generate a list of columns with uppercase names\n    new_columns = [col(c).alias(c.upper()) for c in df.columns]\n    # Select columns with new names\n    return df.select(*new_columns)\n\n# Base URL and list of files\nurl_base = 'https://github.com/sfc-gh-mconsoli/eredivisie_prediction/raw/main/dataset/'\nurl_files = [\n    'eredivisie_history.csv',\n    'eredivisie_fixture.csv'\n]\n\n# Loop through each URL\nfor url in url_files:\n    # Get Snowpark DataFrame from the URL\n    df = fetch_dataset_from_github(url_base + url)\n\n    # Extract table name from URL\n    table_name = url.split('/')[-1].replace('.csv', '').upper()\n\n    # Drop the table if it exists\n    session.sql(f\"DROP TABLE IF EXISTS {table_name}\").collect()\n\n    # Convert column names to uppercase\n    df = rename_columns_to_uppercase(df)\n\n    # Create table and insert data from Snowpark DataFrame\n    df.write.save_as_table(table_name, mode='overwrite')\n\n    print(f\"Table {table_name} created and data loaded successfully.\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fc221afd-5cf4-4877-81f2-341b5a794274",
   "metadata": {
    "language": "python",
    "name": "Verify_Data_Loaded_1",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Let's check loaded data\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark import Session\nimport streamlit as st\n\nsession = get_active_session()\n\neredivisie_history_df = session.table('EREDIVISIE_HISTORY')\n\nst.dataframe(eredivisie_history_df)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "db058f60-3e5b-4a2f-863d-5aa0ff228e59",
   "metadata": {
    "language": "sql",
    "name": "Verify_Data_Loaded_2",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- Verify we loaded data for all seasons\nSELECT YEAR(TO_DATE(\"DATE\",'DD/MM/YYYY')), COUNT(*)\nFROM EREDIVISIE_PREDICTION.PUBLIC.EREDIVISIE_HISTORY\nGROUP BY YEAR(TO_DATE(\"DATE\",'DD/MM/YYYY'))\norder by YEAR(TO_DATE(\"DATE\",'DD/MM/YYYY'))  DESC",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d80c942b-3f67-4594-b779-4ec271a57374",
   "metadata": {
    "language": "python",
    "name": "Winner_Analysis",
    "collapsed": false
   },
   "outputs": [],
   "source": "import streamlit as st\nimport snowflake.snowpark as sp\nimport snowflake.snowpark.functions as F\nimport plotly.express as px\n\n# Filter home wins\nhome_wins = (\n    eredivisie_history_df.filter(F.col('FTR') == 'H')\n    .group_by('HOMETEAM')\n    .agg(F.count('HOMETEAM').alias('Wins'))\n)\n\n# Filter away wins\naway_wins = (\n    eredivisie_history_df.filter(F.col('FTR') == 'A')\n    .group_by('AWAYTEAM')\n    .agg(F.count('AWAYTEAM').alias('Wins'))\n)\n\n# Rename columns to match for concatenation\nhome_wins = home_wins.select(F.col('HOMETEAM').alias('Team'), 'Wins')\naway_wins = away_wins.select(F.col('AWAYTEAM').alias('Team'), 'Wins')\n\n# Combine home and away wins\ntotal_wins = home_wins.union_all(away_wins).group_by('Team').agg(F.sum('Wins').alias('Total_Wins'))\n\n# Collect the result into a Pandas DataFrame\ntotal_wins_pd = total_wins.to_pandas()\n# Sort by most wins\ntotal_wins_pd = total_wins_pd.sort_values(by='TOTAL_WINS', ascending=False)\n\n# Plotting the chart\n# Function to plot bar chart\ndef plot_bar_chart(df, x_col, y_col, title, labels):\n    fig = px.bar(df, x=x_col, y=y_col, title=title, labels=labels)\n    st.plotly_chart(fig)\n\n# Plot\n# Plot the chart for the team with most wins\nplot_bar_chart(\n    total_wins_pd, \n    'TEAM', \n    'TOTAL_WINS', \n    'Top Teams by Number of Wins', \n    {'TEAM': 'Team', 'TOTAL_WINS': 'Number of Wins'}\n)",
   "execution_count": null
  }
 ]
}